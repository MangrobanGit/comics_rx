{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comics Rx\n",
    "## [A comic book recommendation system](https://github.com/MangrobanGit/comics_rx)\n",
    "<img src=\"https://images.unsplash.com/photo-1514329926535-7f6dbfbfb114?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=2850&q=80\" width=\"400\" align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - ALS Model - Reduced Data\n",
    "\n",
    "This time, as explored in the EDA NB, let's consider removing customers who we feel have too few or too many purchases to influence the model in the intended way.\n",
    "\n",
    "Examples:\n",
    "- Too few - Customers who have only bought 1 comic (series).\n",
    "- Too many - Customers with > 1000 series (for example, think all eBay customers are rolled into one account number)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2  # 1 would be where you need to specify the files\n",
    "#%aimport data_fcns\n",
    "\n",
    "import pandas as pd  # dataframes\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Data storage\n",
    "from sqlalchemy import create_engine  # SQL helper\n",
    "import psycopg2 as psql  #PostgreSQL DBs\n",
    "\n",
    "# import necessary libraries\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# from pyspark.sql.types import (StructType, StructField, IntegerType\n",
    "#                                ,FloatType, LongType, StringType)\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, explode, lit, isnan, when, count\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom\n",
    "import data_fcns as dfc\n",
    "import keys  # Custom keys lib\n",
    "import comic_recs as cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate SparkSession object\n",
    "spark = pyspark.sql.SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "# spark = SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "\n",
    "There is way to directly hit PostgreSQL through JDBC, but I don't know how to do that yet. So have worked around by saving the candidate dataset to JSON, and then will use that as input to Spark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have previously created a version of the transactions table and filtered it down.\n",
    "trans = spark.read.json('raw_data/trans_filtered_floor.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, date_sold: bigint, item_id: string, publisher: string, qty_sold: bigint, title_and_num: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persist the data\n",
    "trans.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288062 7\n"
     ]
    }
   ],
   "source": [
    "print(trans.count(), len(trans.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_num: string (nullable = true)\n",
      " |-- comic_title: string (nullable = true)\n",
      " |-- date_sold: long (nullable = true)\n",
      " |-- item_id: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- qty_sold: long (nullable = true)\n",
      " |-- title_and_num: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check schema\n",
    "trans.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More exploration/testing\n",
    "\n",
    "We won't be using pandas dataframes in the matrix factorization through Spark, but let's cast to one anyway as it will be easier to work with for EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 288062 entries, 0 to 288061\n",
      "Data columns (total 7 columns):\n",
      "account_num      288062 non-null object\n",
      "comic_title      288062 non-null object\n",
      "date_sold        288062 non-null int64\n",
      "item_id          288062 non-null object\n",
      "publisher        288062 non-null object\n",
      "qty_sold         288062 non-null int64\n",
      "title_and_num    288062 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 15.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# cast to Pandas dataframe to turn timestamp data to datetime and check nulls.\n",
    "trans_df = trans.select('*').toPandas()\n",
    "trans_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_num</th>\n",
       "      <th>comic_title</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>item_id</th>\n",
       "      <th>publisher</th>\n",
       "      <th>qty_sold</th>\n",
       "      <th>title_and_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01033</td>\n",
       "      <td>Afterlife With Archie (Archie)</td>\n",
       "      <td>1390505789000</td>\n",
       "      <td>DCD630105</td>\n",
       "      <td>Archie Comics</td>\n",
       "      <td>1</td>\n",
       "      <td>Afterlife With Archie #1 2nd P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01333</td>\n",
       "      <td>Afterlife With Archie (Archie)</td>\n",
       "      <td>1398947834000</td>\n",
       "      <td>DCD630105</td>\n",
       "      <td>Archie Comics</td>\n",
       "      <td>1</td>\n",
       "      <td>Afterlife With Archie #1 2nd P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00946</td>\n",
       "      <td>Afterlife With Archie (Archie)</td>\n",
       "      <td>1399904156000</td>\n",
       "      <td>DCD630105</td>\n",
       "      <td>Archie Comics</td>\n",
       "      <td>1</td>\n",
       "      <td>Afterlife With Archie #1 2nd P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01278</td>\n",
       "      <td>Afterlife With Archie (Archie)</td>\n",
       "      <td>1407954335000</td>\n",
       "      <td>DCD630105</td>\n",
       "      <td>Archie Comics</td>\n",
       "      <td>1</td>\n",
       "      <td>Afterlife With Archie #1 2nd P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01212</td>\n",
       "      <td>Afterlife With Archie (Archie)</td>\n",
       "      <td>1383751270000</td>\n",
       "      <td>DCD630105</td>\n",
       "      <td>Archie Comics</td>\n",
       "      <td>1</td>\n",
       "      <td>Afterlife With Archie #1 2nd P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  account_num                     comic_title      date_sold    item_id  \\\n",
       "0       01033  Afterlife With Archie (Archie)  1390505789000  DCD630105   \n",
       "1       01333  Afterlife With Archie (Archie)  1398947834000  DCD630105   \n",
       "2       00946  Afterlife With Archie (Archie)  1399904156000  DCD630105   \n",
       "3       01278  Afterlife With Archie (Archie)  1407954335000  DCD630105   \n",
       "4       01212  Afterlife With Archie (Archie)  1383751270000  DCD630105   \n",
       "\n",
       "       publisher  qty_sold                   title_and_num  \n",
       "0  Archie Comics         1  Afterlife With Archie #1 2nd P  \n",
       "1  Archie Comics         1  Afterlife With Archie #1 2nd P  \n",
       "2  Archie Comics         1  Afterlife With Archie #1 2nd P  \n",
       "3  Archie Comics         1  Afterlife With Archie #1 2nd P  \n",
       "4  Archie Comics         1  Afterlife With Archie #1 2nd P  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's double check the data is how we expect it\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df['dt'] = pd.to_datetime(trans_df['date_sold'], unit='ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. Reverse-confirmed versus the original transactions dataframe in the other notebook that this datetime is correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep for ALS\n",
    "\n",
    "Let's aggregate the data to the two columns we need:\n",
    "- `account_num` - This is the identifier for individual customers.\n",
    "\n",
    "\n",
    "- `comic_title` - The comic. Represents individual volumes/runs of a comic.\n",
    "\n",
    "\n",
    "- `score` - We need to figure out what we want to use to act as a `score`. If these were Amazon items then review scores would be natural fit; but we don't have that. We can maybe use a binary flag of `bought`/`not bought`. Or we can use the `qty_sold`. This might be interesting in that it might capture some interesting behavior from comic 'collectors/speculators'. Since this is first pass, I'm curious as to what `qty_sold` might do!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only care about `account_num`, `comic_title` and `qty_sold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, qty_sold: bigint]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comics_sold = trans[['account_num', 'comic_title', 'qty_sold']]\n",
    "comics_sold.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comics_sold = comics_sold.withColumn('bought', lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------+------+\n",
      "|account_num|         comic_title|qty_sold|bought|\n",
      "+-----------+--------------------+--------+------+\n",
      "|      01033|Afterlife With Ar...|       1|     1|\n",
      "|      01333|Afterlife With Ar...|       1|     1|\n",
      "|      00946|Afterlife With Ar...|       1|     1|\n",
      "|      01278|Afterlife With Ar...|       1|     1|\n",
      "|      01212|Afterlife With Ar...|       1|     1|\n",
      "|      00877|Afterlife With Ar...|       1|     1|\n",
      "|      01155|Afterlife With Ar...|       1|     1|\n",
      "|      01099|Afterlife With Ar...|       1|     1|\n",
      "|      00127|Afterlife With Ar...|       1|     1|\n",
      "|      01033|Afterlife With Ar...|       1|     1|\n",
      "+-----------+--------------------+--------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comics_sold.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, qty_sold: bigint]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comics_sold = trans[['account_num', 'comic_title', 'qty_sold']]\n",
    "comics_sold.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, sum(qty_sold): bigint]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_comics_sold = comics_sold.groupBy(['account_num', 'comic_title'\n",
    "                                         ]).agg({'qty_sold': 'sum'})\n",
    "total_comics_sold.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+\n",
      "|account_num|         comic_title|sum(qty_sold)|\n",
      "+-----------+--------------------+-------------+\n",
      "|      00487|Captain Swing (Av...|            2|\n",
      "|      00029|God Is Dead (Avatar)|            7|\n",
      "|      01260| Providence (Avatar)|            1|\n",
      "|      00172|   Supergod (Avatar)|            3|\n",
      "|      00032|Big Trouble In Li...|           11|\n",
      "|      00130|Six Gun Gorilla (...|            3|\n",
      "|      00742|      Unsound (Boom)|            6|\n",
      "|      01406|Age of Reptiles A...|            5|\n",
      "|      00291|Angel & Faith (Da...|            2|\n",
      "|      00032|Baltimore Curse B...|            5|\n",
      "+-----------+--------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_comics_sold.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40174 3\n"
     ]
    }
   ],
   "source": [
    "print(total_comics_sold.count(), len(total_comics_sold.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_comics_sold = total_comics_sold.withColumn('bought', lit(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't like that default column name. Let's fix that to be `qty_sold` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+------+\n",
      "|account_num|         comic_title|sum(qty_sold)|bought|\n",
      "+-----------+--------------------+-------------+------+\n",
      "|      00487|Captain Swing (Av...|            2|     1|\n",
      "|      00029|God Is Dead (Avatar)|            7|     1|\n",
      "|      01260| Providence (Avatar)|            1|     1|\n",
      "|      00172|   Supergod (Avatar)|            3|     1|\n",
      "|      00032|Big Trouble In Li...|           11|     1|\n",
      "|      00130|Six Gun Gorilla (...|            3|     1|\n",
      "|      00742|      Unsound (Boom)|            6|     1|\n",
      "|      01406|Age of Reptiles A...|            5|     1|\n",
      "|      00291|Angel & Faith (Da...|            2|     1|\n",
      "|      00032|Baltimore Curse B...|            5|     1|\n",
      "+-----------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_comics_sold.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_comics_sold = total_comics_sold[['account_num', 'comic_title', 'bought']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40174 3\n"
     ]
    }
   ],
   "source": [
    "print(total_comics_sold.count(), len(total_comics_sold.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting\n",
    "\n",
    "Sooooooo, I forgot that the values need to be numeric. So need to fix that.\n",
    "\n",
    "#### Convert `account_id` to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_int_udf = F.udf(dfc.make_int, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_num_col = total_comics_sold['account_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, bought: int, account_id: int]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_comics_sold = total_comics_sold.withColumn('account_id',\n",
    "                                                 to_int_udf(account_num_col))\n",
    "total_comics_sold.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------+----------+\n",
      "|account_num|         comic_title|bought|account_id|\n",
      "+-----------+--------------------+------+----------+\n",
      "|      00487|Captain Swing (Av...|     1|       487|\n",
      "|      00029|God Is Dead (Avatar)|     1|        29|\n",
      "|      01260| Providence (Avatar)|     1|      1260|\n",
      "|      00172|   Supergod (Avatar)|     1|       172|\n",
      "|      00032|Big Trouble In Li...|     1|        32|\n",
      "|      00130|Six Gun Gorilla (...|     1|       130|\n",
      "|      00742|      Unsound (Boom)|     1|       742|\n",
      "|      01406|Age of Reptiles A...|     1|      1406|\n",
      "|      00291|Angel & Faith (Da...|     1|       291|\n",
      "|      00032|Baltimore Curse B...|     1|        32|\n",
      "+-----------+--------------------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_comics_sold.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40174 4\n"
     ]
    }
   ],
   "source": [
    "print(total_comics_sold.count(), len(total_comics_sold.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to find a way to give ids to the `comic_title`. Kind of clunky, but I do have the version in PostgreSQL of the big table. I can just build an ID table up there as source of truth. I could do something on PySpark side, but then think would want to save it somewhere (e.g. the DB) anyway. So might as well do it from the top.\n",
    "\n",
    "#### Get `comic_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[comic_id: bigint, comic_title: string]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comics = spark.read.json('raw_data/comics.json')\n",
    "comics.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7202"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comics.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|comic_id|         comic_title|\n",
      "+--------+--------------------+\n",
      "|       1|0Secret Wars (Mar...|\n",
      "|       2|100 Bullets Broth...|\n",
      "|       3|100 Penny Press L...|\n",
      "|       4|100 Penny Press S...|\n",
      "|       5|100 Penny Press T...|\n",
      "|       6|100 Penny Press T...|\n",
      "|       7|100th Anniversary...|\n",
      "|       8|12 Reasons To Die...|\n",
      "|       9|    13 Coins (Other)|\n",
      "|      10|13th Artifact One...|\n",
      "+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comics.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7202 2\n"
     ]
    }
   ],
   "source": [
    "print(comics.count(), len(comics.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to join this back into `total_comics_sold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aliases\n",
    "tot = total_comics_sold.alias('tot')\n",
    "com = comics.alias('com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+\n",
      "|account_id|comic_id|bought|\n",
      "+----------+--------+------+\n",
      "|       487|    1102|     1|\n",
      "|        29|    2680|     1|\n",
      "|      1260|    4870|     1|\n",
      "|       172|    6023|     1|\n",
      "|        32|     755|     1|\n",
      "|       130|    5497|     1|\n",
      "|       742|    6717|     1|\n",
      "|      1406|     136|     1|\n",
      "|       291|     260|     1|\n",
      "|        32|     525|     1|\n",
      "+----------+--------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tot_sold_ids_only = tot.join(com.select('comic_id', 'comic_title'),\n",
    "                             tot.comic_title == com.comic_title).select(\n",
    "                                 'account_id', 'comic_id', 'bought')\n",
    "tot_sold_ids_only.persist()\n",
    "tot_sold_ids_only.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_id: integer (nullable = true)\n",
      " |-- comic_id: long (nullable = true)\n",
      " |-- bought: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tot_sold_ids_only.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40174 3\n"
     ]
    }
   ],
   "source": [
    "print(tot_sold_ids_only.count(), len(tot_sold_ids_only.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save this intermediate table.\n",
    "\n",
    "To save work, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_input_df = tot_sold_ids_only.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40174, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_input_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_input_df.to_json('raw_data/als_input_filtered_floor.json',\n",
    "                     orient='records',\n",
    "                     lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"account_id\":2247,\"comic_id\":995,\"bought\":1}\r\n",
      "{\"account_id\":487,\"comic_id\":1102,\"bought\":1}\r\n",
      "{\"account_id\":29,\"comic_id\":2680,\"bought\":1}\r\n",
      "{\"account_id\":1260,\"comic_id\":4870,\"bought\":1}\r\n",
      "{\"account_id\":172,\"comic_id\":6023,\"bought\":1}\r\n",
      "{\"account_id\":2493,\"comic_id\":66,\"bought\":1}\r\n",
      "{\"account_id\":52,\"comic_id\":116,\"bought\":1}\r\n",
      "{\"account_id\":32,\"comic_id\":755,\"bought\":1}\r\n",
      "{\"account_id\":1149,\"comic_id\":971,\"bought\":1}\r\n",
      "{\"account_id\":1489,\"comic_id\":3503,\"bought\":1}\r\n"
     ]
    }
   ],
   "source": [
    "!head raw_data/als_input_filtered.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
